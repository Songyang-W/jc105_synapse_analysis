{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a60dae-ce9a-4780-97df-956bf3cb44b8",
   "metadata": {},
   "source": [
    "# code demo for both calculate_close_axon_dend_contacts.py and visualize_close_axon_dend_contacts.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337a358",
   "metadata": {},
   "source": [
    "# Close Axon–Dendrite Contacts: Calculation + Visualization (Demo Notebook)\n",
    "\n",
    "This notebook shows an end-to-end workflow to:\n",
    "1. **Build/annotate two neurons** (axon/dendrite labels per skeleton vertex).\n",
    "2. **Find close axon↔dendrite vertex pairs** within a distance threshold.\n",
    "3. **Cluster matches into regions** using **skeleton connectivity on both neurons**.\n",
    "4. **Visualize** results in Neuroglancer via **one line per region midpoint** (both directions on the same link).\n",
    "\n",
    "> **Notes**\n",
    "> - Keep your dataset + credentials ready for `caveclient`/`pcg_skel` usage.\n",
    "> - Adjust the configuration cell to your own datastack + IDs.\n",
    "> - The logic mirrors the scripts we prepared—just packaged for a sharable notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ad5e5",
   "metadata": {},
   "source": [
    "## 1. Configuration & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ded3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to datastack: jchen_mouse_cortex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import caveclient\n",
    "import pcg_skel\n",
    "import skeleton_plot as skelplot\n",
    "from scipy.spatial import cKDTree\n",
    "from nglui.statebuilder import ViewerState, ImageLayer, SegmentationLayer\n",
    "from heapq import heappush, heappop\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---- Edit these values for your run ----\n",
    "DATASTACK = \"jchen_mouse_cortex\"\n",
    "ROOT_ID1 = 720575941071680793\n",
    "SOMA1 = [168103, 158705, 2257]\n",
    "ROOT_ID2 = 720575941057622500\n",
    "SOMA2 = [170885, 158942, 3651]\n",
    "ROOT_RESOLUTION = (7.5, 7.5, 50)  # nm/px\n",
    "COLLAPSE_RADIUS = 7500\n",
    "AXON_QUALITY_THRESH = 0.2\n",
    "DIST_THRESHOLD_NM = 5000.0\n",
    "MAX_PAIRS_PER_DIR = 5000\n",
    "\n",
    "client = caveclient.CAVEclient(DATASTACK)\n",
    "print('Connected to datastack:', DATASTACK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852689f",
   "metadata": {},
   "source": [
    "## 2. Small Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7e4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nm_to_px(x_nm, res=ROOT_RESOLUTION):\n",
    "    x_nm = np.asarray(x_nm, dtype=float)\n",
    "    return x_nm / np.asarray(res, dtype=float)\n",
    "\n",
    "def px_to_nm(x_px, res=ROOT_RESOLUTION):\n",
    "    x_px = np.asarray(x_px, dtype=float)\n",
    "    return x_px * np.asarray(res, dtype=float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a59847",
   "metadata": {},
   "source": [
    "## 3. Project Mesh Annotations → Skeleton Compartments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bdba935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_skel_compartments_from_mesh_annos(\n",
    "    nrn,\n",
    "    skel,\n",
    "    axon_anno=\"is_axon\",\n",
    "    apical_anno=None,\n",
    "    basal_anno=None,\n",
    "    default_non_axon=3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Project mesh-level annotations to a full per-skeleton-vertex label array.\n",
    "    Labels: 2='axon', 3='basal', 4='apical', or default_non_axon elsewhere.\n",
    "    Also writes skel.vertex_properties['compartment'].\n",
    "    \"\"\"\n",
    "    def _mesh_bool_from_anno(name):\n",
    "        if name is None or not hasattr(nrn.anno, name):\n",
    "            return None\n",
    "        df = getattr(nrn.anno, name).df  # expects 'mesh_index' or 'mesh_ind'\n",
    "        if \"mesh_index\" not in df.columns:\n",
    "            col = \"mesh_ind\" if \"mesh_ind\" in df.columns else None\n",
    "            if col is None:\n",
    "                raise ValueError(f\"{name} has no mesh_index/mesh_ind column.\")\n",
    "            idxs = df[col].to_numpy()\n",
    "        else:\n",
    "            idxs = df[\"mesh_index\"].to_numpy()\n",
    "        return set(np.asarray(idxs, dtype=np.int64))\n",
    "\n",
    "    axon_mesh = _mesh_bool_from_anno(axon_anno)\n",
    "    apical_mesh = _mesh_bool_from_anno(apical_anno) if apical_anno else None\n",
    "    basal_mesh = _mesh_bool_from_anno(basal_anno) if basal_anno else None\n",
    "\n",
    "    if not hasattr(skel, \"mesh_index\") or skel.mesh_index is None:\n",
    "        raise ValueError(\"skel.mesh_index is required.\")\n",
    "    sk_mi = np.asarray(skel.mesh_index, dtype=np.int64)\n",
    "\n",
    "    comp = np.full(len(sk_mi), default_non_axon, dtype=int)\n",
    "    if axon_mesh:\n",
    "        comp[np.isin(sk_mi, list(axon_mesh))] = 2\n",
    "    if apical_mesh:\n",
    "        comp[np.isin(sk_mi, list(apical_mesh))] = 4\n",
    "    if basal_mesh:\n",
    "        comp[np.isin(sk_mi, list(basal_mesh))] = 3\n",
    "\n",
    "    comp = np.where(comp == None, default_non_axon, comp)  # noqa: E711\n",
    "    skel.vertex_properties[\"compartment\"] = comp\n",
    "    return comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebaabf5",
   "metadata": {},
   "source": [
    "## 4. Build Two Neurons & Annotate Axon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0b7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_two_neurons_with_is_axon(\n",
    "    root_id1, soma_location1,\n",
    "    root_id2, soma_location2,\n",
    "    client,\n",
    "    root_resolution=ROOT_RESOLUTION,\n",
    "    collapse_radius=COLLAPSE_RADIUS,\n",
    "    threshold_quality=AXON_QUALITY_THRESH,\n",
    "):\n",
    "    skel1, mesh1, (l2_to_skel1, skel_to_l21) = pcg_skel.pcg_skeleton(\n",
    "        root_id1, client, return_mesh=True,\n",
    "        root_point=soma_location1, root_point_resolution=root_resolution,\n",
    "        collapse_soma=True, collapse_radius=collapse_radius,\n",
    "        return_l2dict=True,\n",
    "    )\n",
    "    nrn1 = pcg_skel.pcg_meshwork(\n",
    "        root_id=root_id1, client=client,\n",
    "        root_point=soma_location1, root_point_resolution=root_resolution,\n",
    "        collapse_soma=True, collapse_radius=collapse_radius,\n",
    "        synapses=True,\n",
    "    )\n",
    "    pcg_skel.features.add_synapse_count(nrn1)\n",
    "    pcg_skel.features.add_is_axon_annotation(\n",
    "        nrn1, pre_anno=\"pre_syn\", post_anno=\"post_syn\",\n",
    "        annotation_name=\"is_axon\", return_quality=True,\n",
    "        threshold_quality=threshold_quality,\n",
    "    )\n",
    "\n",
    "    skel2, mesh2, (l2_to_skel2, skel_to_l22) = pcg_skel.pcg_skeleton(\n",
    "        root_id2, client, return_mesh=True,\n",
    "        root_point=soma_location2, root_point_resolution=root_resolution,\n",
    "        collapse_soma=True, collapse_radius=collapse_radius,\n",
    "        return_l2dict=True,\n",
    "    )\n",
    "    nrn2 = pcg_skel.pcg_meshwork(\n",
    "        root_id=root_id2, client=client,\n",
    "        root_point=soma_location2, root_point_resolution=root_resolution,\n",
    "        collapse_soma=True, collapse_radius=collapse_radius,\n",
    "        synapses=True,\n",
    "    )\n",
    "    pcg_skel.features.add_synapse_count(nrn2)\n",
    "    pcg_skel.features.add_is_axon_annotation(\n",
    "        nrn2, pre_anno=\"pre_syn\", post_anno=\"post_syn\",\n",
    "        annotation_name=\"is_axon\", return_quality=True,\n",
    "        threshold_quality=threshold_quality,\n",
    "    )\n",
    "\n",
    "    comp1 = build_skel_compartments_from_mesh_annos(nrn1, skel1, axon_anno=\"is_axon\")\n",
    "    comp2 = build_skel_compartments_from_mesh_annos(nrn2, skel2, axon_anno=\"is_axon\")\n",
    "    return (skel1, nrn1, comp1, skel2, nrn2, comp2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75f69b",
   "metadata": {},
   "source": [
    "## 5. Find Close Axon↔Dendrite Vertex Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1121bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_pairs_within_threshold(A_nm, B_nm, thr_nm, use_kdtree=True):\n",
    "    \"\"\"Return (pairs, dists) for points within <= thr_nm (nm).\"\"\"\n",
    "    if A_nm.size == 0 or B_nm.size == 0:\n",
    "        return np.empty((0,2), dtype=int), np.empty((0,), dtype=float)\n",
    "\n",
    "    if use_kdtree:\n",
    "        try:\n",
    "            tree = cKDTree(B_nm)\n",
    "            neigh = tree.query_ball_point(A_nm, r=thr_nm)\n",
    "            pairs, dists = [], []\n",
    "            for i, js in enumerate(neigh):\n",
    "                if not js: continue\n",
    "                a = A_nm[i]\n",
    "                bsel = B_nm[np.asarray(js, dtype=int)]\n",
    "                ds = np.linalg.norm(bsel - a, axis=1)\n",
    "                dists.extend(ds.tolist())\n",
    "                gi = np.full(len(js), i, dtype=int)\n",
    "                gj = np.asarray(js, dtype=int)\n",
    "                pairs.append(np.stack([gi, gj], axis=1))\n",
    "            if pairs:\n",
    "                pairs = np.concatenate(pairs, axis=0)\n",
    "                dists = np.asarray(dists, dtype=float)\n",
    "            else:\n",
    "                pairs = np.empty((0,2), dtype=int)\n",
    "                dists = np.empty((0,), dtype=float)\n",
    "            return pairs, dists\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    thr2 = float(thr_nm) ** 2\n",
    "    A2 = np.sum(A_nm*A_nm, axis=1, keepdims=True)\n",
    "    B2 = np.sum(B_nm*B_nm, axis=1, keepdims=True).T\n",
    "    AB = A_nm @ B_nm.T\n",
    "    dist2 = A2 + B2 - 2.0 * AB\n",
    "    np.maximum(dist2, 0.0, out=dist2)\n",
    "    ai, bj = np.where(dist2 <= thr2)\n",
    "    if ai.size == 0:\n",
    "        return np.empty((0,2), dtype=int), np.empty((0,), dtype=float)\n",
    "    pairs = np.stack([ai, bj], axis=1)\n",
    "    dists = np.sqrt(dist2[ai, bj], dtype=float)\n",
    "    return pairs, dists\n",
    "\n",
    "\n",
    "def compute_close_pairs_and_meta(\n",
    "    root_id1, verts1_nm, comp1,\n",
    "    root_id2, verts2_nm, comp2,\n",
    "    threshold_nm=DIST_THRESHOLD_NM,\n",
    "    root_resolution=ROOT_RESOLUTION,\n",
    "    max_pairs_per_dir=MAX_PAIRS_PER_DIR,\n",
    "    dendrite_labels=(3, 4),\n",
    "):\n",
    "    axon_label = 2\n",
    "    verts1_nm = np.asarray(verts1_nm, dtype=float)\n",
    "    verts2_nm = np.asarray(verts2_nm, dtype=float)\n",
    "    comp1 = np.asarray(comp1); comp2 = np.asarray(comp2)\n",
    "\n",
    "    mask1_ax = (comp1 == axon_label); mask1_dn = np.isin(comp1, dendrite_labels)\n",
    "    mask2_ax = (comp2 == axon_label); mask2_dn = np.isin(comp2, dendrite_labels)\n",
    "\n",
    "    v1_ax_nm = verts1_nm[mask1_ax]; v1_dn_nm = verts1_nm[mask1_dn]\n",
    "    v2_ax_nm = verts2_nm[mask2_ax]; v2_dn_nm = verts2_nm[mask2_dn]\n",
    "\n",
    "    pairs_1ax_2dn, dists_12 = _find_pairs_within_threshold(v1_ax_nm, v2_dn_nm, threshold_nm)\n",
    "    pairs_2ax_1dn, dists_21 = _find_pairs_within_threshold(v2_ax_nm, v1_dn_nm, threshold_nm)\n",
    "\n",
    "    def _cap(p, d):\n",
    "        if p.shape[0] <= max_pairs_per_dir: return p, d\n",
    "        idx = np.linspace(0, p.shape[0]-1, max_pairs_per_dir, dtype=int)\n",
    "        return p[idx], (d[idx] if d is not None and d.size else d)\n",
    "\n",
    "    pairs_1ax_2dn, dists_12 = _cap(pairs_1ax_2dn, dists_12)\n",
    "    pairs_2ax_1dn, dists_21 = _cap(pairs_2ax_1dn, dists_21)\n",
    "\n",
    "    idx1_all = np.arange(verts1_nm.shape[0]); idx2_all = np.arange(verts2_nm.shape[0])\n",
    "    idx1_ax = idx1_all[mask1_ax]; idx1_dn = idx1_all[mask1_dn]\n",
    "    idx2_ax = idx2_all[mask2_ax]; idx2_dn = idx2_all[mask2_dn]\n",
    "\n",
    "    global_pairs_12 = np.column_stack([idx1_ax[pairs_1ax_2dn[:,0]], idx2_dn[pairs_1ax_2dn[:,1]]]).astype(int)\n",
    "    global_pairs_21 = np.column_stack([idx2_ax[pairs_2ax_1dn[:,0]], idx1_dn[pairs_2ax_1dn[:,1]]]).astype(int)\n",
    "\n",
    "    meta = {\n",
    "        \"n_pairs_1axon_2dend\": int(global_pairs_12.shape[0]),\n",
    "        \"n_pairs_2axon_1dend\": int(global_pairs_21.shape[0]),\n",
    "        \"threshold_nm\": float(threshold_nm),\n",
    "        \"resolution_nm_per_pixel\": tuple(float(x) for x in root_resolution),\n",
    "    }\n",
    "    return meta, global_pairs_12, global_pairs_21, dists_12, dists_21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c221110",
   "metadata": {},
   "source": [
    "## 6. Cluster Pairs into Regions Using Skeleton Connectivity (Both Sides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4910d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj_from_edges(edges):\n",
    "    adj = defaultdict(list)\n",
    "    for u, v in np.asarray(edges, dtype=int):\n",
    "        adj[u].append(v)\n",
    "        adj[v].append(u)\n",
    "    return adj\n",
    "\n",
    "def k_hop_neighborhoods(adj, seeds, k=1):\n",
    "    seeds = list(map(int, set(seeds)))\n",
    "    out = {s: set([s]) for s in seeds}\n",
    "    for s in seeds:\n",
    "        if k <= 0: continue\n",
    "        seen = {s}\n",
    "        q = deque([(s, 0)])\n",
    "        while q:\n",
    "            u, d = q.popleft()\n",
    "            if d == k: continue\n",
    "            for w in adj.get(u, []):\n",
    "                if w not in seen:\n",
    "                    seen.add(w); out[s].add(w); q.append((w, d+1))\n",
    "    return out\n",
    "\n",
    "def dijkstra_subset_weighted(adj, coords_nm, start, allowed):\n",
    "    allowed = set(allowed)\n",
    "    if start not in allowed: return {}\n",
    "    dist = {start: 0.0}; pq = [(0.0, start)]\n",
    "    while pq:\n",
    "        du, u = heappop(pq)\n",
    "        if du > dist[u]: continue\n",
    "        for v in adj.get(u, []):\n",
    "            if v not in allowed: continue\n",
    "            w = float(np.linalg.norm(coords_nm[u] - coords_nm[v]))\n",
    "            alt = du + w\n",
    "            if v not in dist or alt < dist[v]:\n",
    "                dist[v] = alt; heappush(pq, (alt, v))\n",
    "    return dist\n",
    "\n",
    "def induced_geodesic_diameter(adj, coords_nm, nodes_subset):\n",
    "    nodes = list(set(map(int, nodes_subset)))\n",
    "    if len(nodes) <= 1:\n",
    "        return 0.0, (nodes[0] if nodes else None, nodes[0] if nodes else None)\n",
    "    best_len = 0.0; best_pair = (nodes[0], nodes[0]); allowed = set(nodes)\n",
    "    for s in nodes:\n",
    "        dist = dijkstra_subset_weighted(adj, coords_nm, s, allowed)\n",
    "        if not dist: continue\n",
    "        v = max(dist, key=dist.get)\n",
    "        if dist[v] > best_len:\n",
    "            best_len = dist[v]; best_pair = (s, v)\n",
    "    return float(best_len), best_pair\n",
    "\n",
    "def cluster_pairs_by_skeleton_connectivity(\n",
    "    pairs, edgesA, edgesB, coordsA_nm, coordsB_nm, hop_tol_A=1, hop_tol_B=1\n",
    "):\n",
    "    pairs = np.asarray(pairs, dtype=int)\n",
    "    if pairs.size == 0: return []\n",
    "\n",
    "    adjA = build_adj_from_edges(edgesA); adjB = build_adj_from_edges(edgesB)\n",
    "    A_verts = pairs[:,0]; B_verts = pairs[:,1]\n",
    "    A_khop = k_hop_neighborhoods(adjA, A_verts, k=hop_tol_A)\n",
    "    B_khop = k_hop_neighborhoods(adjB, B_verts, k=hop_tol_B)\n",
    "\n",
    "    M = pairs.shape[0]; pair_adj = [[] for _ in range(M)]\n",
    "    for i in range(M):\n",
    "        a_i, b_i = int(pairs[i,0]), int(pairs[i,1])\n",
    "        A_near = A_khop.get(a_i, {a_i}); B_near = B_khop.get(b_i, {b_i})\n",
    "        for j in range(i+1, M):\n",
    "            a_j, b_j = int(pairs[j,0]), int(pairs[j,1])\n",
    "            if (a_j in A_near) and (b_j in B_near):\n",
    "                pair_adj[i].append(j); pair_adj[j].append(i)\n",
    "\n",
    "    seen = np.zeros(M, dtype=bool); comps = []\n",
    "    for i in range(M):\n",
    "        if seen[i]: continue\n",
    "        stack=[i]; seen[i]=True; comp=[i]\n",
    "        while stack:\n",
    "            u=stack.pop()\n",
    "            for v in pair_adj[u]:\n",
    "                if not seen[v]:\n",
    "                    seen[v]=True; stack.append(v); comp.append(v)\n",
    "        comps.append(np.array(comp, dtype=int))\n",
    "\n",
    "    regions = []\n",
    "    for rows in comps:\n",
    "        A_nodes = np.unique(pairs[rows,0])\n",
    "        B_nodes = np.unique(pairs[rows,1])\n",
    "        A_diam_nm, (Au, Av) = induced_geodesic_diameter(adjA, coordsA_nm, A_nodes)\n",
    "        B_diam_nm, (Bu, Bv) = induced_geodesic_diameter(adjB, coordsB_nm, B_nodes)\n",
    "        regions.append({\n",
    "            \"pair_rows\": rows,\n",
    "            \"A_vertices\": A_nodes,\n",
    "            \"B_vertices\": B_nodes,\n",
    "            \"A_diameter_nm\": float(A_diam_nm),\n",
    "            \"B_diameter_nm\": float(B_diam_nm),\n",
    "            \"overlap_distance_nm\": float(min(A_diam_nm, B_diam_nm)),\n",
    "            \"A_endpoints\": (int(Au) if Au is not None else None,\n",
    "                            int(Av) if Av is not None else None),\n",
    "            \"B_endpoints\": (int(Bu) if Bu is not None else None,\n",
    "                            int(Bv) if Bv is not None else None),\n",
    "            \"n_pairs\": int(len(rows)),\n",
    "            \"n_A_vertices\": int(len(A_nodes)),\n",
    "            \"n_B_vertices\": int(len(B_nodes)),\n",
    "        })\n",
    "    regions.sort(key=lambda r: r[\"overlap_distance_nm\"], reverse=True)\n",
    "    return regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbac14",
   "metadata": {},
   "source": [
    "## 7. Visualize Regions as Midpoint Lines (Single Neuroglancer Link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f204b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions_midpoint_lines(regions, coordsA_nm, coordsB_nm, root_resolution, method='centroid'):\n",
    "    A_px, B_px = [], []\n",
    "    for r in regions:\n",
    "        if method == 'centroid':\n",
    "            A_mid_nm = coordsA_nm[np.asarray(r[\"A_vertices\"], dtype=int)].mean(axis=0)\n",
    "            B_mid_nm = coordsB_nm[np.asarray(r[\"B_vertices\"], dtype=int)].mean(axis=0)\n",
    "        elif method == 'endpoints':\n",
    "            Au, Av = r.get(\"A_endpoints\", (None, None))\n",
    "            Bu, Bv = r.get(\"B_endpoints\", (None, None))\n",
    "            if None in (Au, Av, Bu, Bv):\n",
    "                A_mid_nm = coordsA_nm[np.asarray(r[\"A_vertices\"], dtype=int)].mean(axis=0)\n",
    "                B_mid_nm = coordsB_nm[np.asarray(r[\"B_vertices\"], dtype=int)].mean(axis=0)\n",
    "            else:\n",
    "                A_mid_nm = 0.5*(coordsA_nm[int(Au)] + coordsA_nm[int(Av)])\n",
    "                B_mid_nm = 0.5*(coordsB_nm[int(Bu)] + coordsB_nm[int(Bv)])\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'centroid' or 'endpoints'\")\n",
    "        A_px.append(tuple(nm_to_px(A_mid_nm, root_resolution).tolist()))\n",
    "        B_px.append(tuple(nm_to_px(B_mid_nm, root_resolution).tolist()))\n",
    "    return A_px, B_px\n",
    "\n",
    "def build_combined_midpoint_link(\n",
    "    root_id1, root_id2,\n",
    "    regions_12, regions_21,\n",
    "    coords1_nm, coords2_nm,\n",
    "    root_resolution,\n",
    "    method='centroid',\n",
    "    IMAGE_SOURCE_URL='precomputed://gs://zetta_jchen_mouse_cortex_001_alignment/img',\n",
    "    SEG_SOURCE_URL='graphene://middleauth+https://cave.fanc-fly.com/segmentation/table/jchen_mouse_cortex/',\n",
    "    client=None,\n",
    "    color_12='gold',\n",
    "    color_21='deepskyblue'\n",
    "):\n",
    "    A12_mid, B12_mid = regions_midpoint_lines(regions_12, coords1_nm, coords2_nm, root_resolution, method)\n",
    "    A21_mid, B21_mid = regions_midpoint_lines(regions_21, coords2_nm, coords1_nm, root_resolution, method)\n",
    "\n",
    "    v = (\n",
    "        ViewerState()\n",
    "        .add_layer(ImageLayer(source=IMAGE_SOURCE_URL))\n",
    "        .add_layer(\n",
    "            SegmentationLayer()\n",
    "            .add_source(SEG_SOURCE_URL)\n",
    "            .add_segments([int(root_id1), int(root_id2)])\n",
    "        )\n",
    "    )\n",
    "    v = v.add_lines(\n",
    "        name=f\"{root_id1} → {root_id2} region midpoints ({method})\",\n",
    "        point_a_column=A12_mid, point_b_column=B12_mid, color=color_12\n",
    "    )\n",
    "    v = v.add_lines(\n",
    "        name=f\"{root_id2} → {root_id1} region midpoints ({method})\",\n",
    "        point_a_column=A21_mid, point_b_column=B21_mid, color=color_21\n",
    "    )\n",
    "    return v.to_link_shortener(client=client) if client is not None else v.to_url()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76275fe1",
   "metadata": {},
   "source": [
    "## 8. Run End-to-End\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425baf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deprecation: this method is to facilitate beta testing of this feature,             it will likely get removed in future versions. \n",
      "WARNING:root:Deprecation: this method is to facilitate beta testing of this feature,             it will likely get removed in future versions. \n",
      "WARNING:root:Deprecation: this method is to facilitate beta testing of this feature,             it will likely get removed in future versions. \n",
      "WARNING:root:Deprecation: this method is to facilitate beta testing of this feature,             it will likely get removed in future versions. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs 1→2: 28 | Pairs 2→1: 13\n",
      "Regions 1→2: 8 | Regions 2→1: 2\n"
     ]
    }
   ],
   "source": [
    "# Build neurons + compartments\n",
    "skel1, nrn1, comp1, skel2, nrn2, comp2 = build_two_neurons_with_is_axon(\n",
    "    ROOT_ID1, SOMA1, ROOT_ID2, SOMA2, client,\n",
    "    root_resolution=ROOT_RESOLUTION,\n",
    "    collapse_radius=COLLAPSE_RADIUS,\n",
    "    threshold_quality=AXON_QUALITY_THRESH,\n",
    ")\n",
    "\n",
    "# Find close pairs\n",
    "meta, gp12, gp21, d12, d21 = compute_close_pairs_and_meta(\n",
    "    ROOT_ID1, skel1.vertices, comp1,\n",
    "    ROOT_ID2, skel2.vertices, comp2,\n",
    "    threshold_nm=DIST_THRESHOLD_NM,\n",
    "    root_resolution=ROOT_RESOLUTION,\n",
    "    max_pairs_per_dir=MAX_PAIRS_PER_DIR\n",
    ")\n",
    "print('Pairs 1→2:', meta['n_pairs_1axon_2dend'], '| Pairs 2→1:', meta['n_pairs_2axon_1dend'])\n",
    "\n",
    "# Cluster into regions using skeleton connectivity on both sides\n",
    "regions_12 = cluster_pairs_by_skeleton_connectivity(\n",
    "    gp12, skel1.edges, skel2.edges, skel1.vertices, skel2.vertices, hop_tol_A=1, hop_tol_B=1\n",
    ")\n",
    "regions_21 = cluster_pairs_by_skeleton_connectivity(\n",
    "    gp21, skel2.edges, skel1.edges, skel2.vertices, skel1.vertices, hop_tol_A=1, hop_tol_B=1\n",
    ")\n",
    "print(f\"Regions 1→2: {len(regions_12)} | Regions 2→1: {len(regions_21)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37f5aa",
   "metadata": {},
   "source": [
    "## 9. Build a Single Neuroglancer Link for Both Directions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0456c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Neuroglancer link (both directions):\n",
      "https://spelunker.cave-explorer.org/#!middleauth+https://global.daf-apis.com/nglstate/api/v1/5399438355857408\n"
     ]
    }
   ],
   "source": [
    "# Optional: short URLs if you pass a CAVEclient (already available as `client`)\n",
    "link_both = build_combined_midpoint_link(\n",
    "    ROOT_ID1, ROOT_ID2,\n",
    "    regions_12, regions_21,\n",
    "    coords1_nm=skel1.vertices, coords2_nm=skel2.vertices,\n",
    "    root_resolution=ROOT_RESOLUTION,\n",
    "    method='centroid',\n",
    "    client=client\n",
    ")\n",
    "print('Neuroglancer link (both directions):')\n",
    "print(link_both)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89540822",
   "metadata": {},
   "source": [
    "## 10. (Optional) Save a Small Artifact Bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363af57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = \"close_contacts_artifacts_demo.npz\"\n",
    "np.savez(\n",
    "    OUT_PATH,\n",
    "    root_id1=np.array([ROOT_ID1], dtype=np.int64),\n",
    "    root_id2=np.array([ROOT_ID2], dtype=np.int64),\n",
    "    root_resolution=np.array(ROOT_RESOLUTION, dtype=float),\n",
    "    skel1_vertices=skel1.vertices, skel2_vertices=skel2.vertices,\n",
    "    skel1_edges=skel1.edges, skel2_edges=skel2.edges,\n",
    "    global_pairs_1axon_2dend=gp12, global_pairs_2axon_1dend=gp21,\n",
    "    dists_1axon_2dend_nm=d12, dists_2axon_1dend_nm=d21\n",
    ")\n",
    "print(f\"[saved] {OUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
